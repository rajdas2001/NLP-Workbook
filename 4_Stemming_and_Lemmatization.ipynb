{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnLtLh+Tz4hZVHbXi+znBT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdas2001/NLP-Workbook/blob/main/4_Stemming_and_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming in NLTK"
      ],
      "metadata": {
        "id": "9Cn6tlMApn_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\", \"dogs\", \"abaci\"]"
      ],
      "metadata": {
        "id": "8z9oAVnDpuk3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXipe0aipCMn",
        "outputId": "0e87aaa7-3017-4d6f-d86c-772c07e22e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating --> eat\n",
            "eats --> eat\n",
            "eat --> eat\n",
            "ate --> ate\n",
            "adjustable --> adjust\n",
            "rafting --> raft\n",
            "ability --> abil\n",
            "meeting --> meet\n",
            "dogs --> dog\n",
            "abaci --> abaci\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "for word in words:\n",
        "    print(word, \"-->\", stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "#the stemmer requires a language parameter\n",
        "snow_stemmer = SnowballStemmer(language='english')\n",
        "for word in words:\n",
        "  print(word, \"-->\", snow_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od8j4_nopxvl",
        "outputId": "e0985f9b-b16e-4e3c-93c8-738d1bb8b9e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating --> eat\n",
            "eats --> eat\n",
            "eat --> eat\n",
            "ate --> ate\n",
            "adjustable --> adjust\n",
            "rafting --> raft\n",
            "ability --> abil\n",
            "meeting --> meet\n",
            "dogs --> dog\n",
            "abaci --> abaci\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization in NLTK"
      ],
      "metadata": {
        "id": "AB57BCZ_rHSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import these modules\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        "\n",
        "# a denotes adjective in \"pos\"\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos=\"a\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLq4P-qjqw6x",
        "outputId": "22774cd0-b7b3-462a-c5fa-cbddc68235f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word, \"-->\", lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ6YH_3trlTl",
        "outputId": "3a40ce12-37d5-476a-efa7-3afa1b6b7290"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating --> eating\n",
            "eats --> eats\n",
            "eat --> eat\n",
            "ate --> ate\n",
            "adjustable --> adjustable\n",
            "rafting --> rafting\n",
            "ability --> ability\n",
            "meeting --> meeting\n",
            "dogs --> dog\n",
            "abaci --> abacus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization in Spacy"
      ],
      "metadata": {
        "id": "aqgppnl7qvVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing\")\n",
        "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
        "for token in doc:\n",
        "    print(token, \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "proj-_h0qvBt",
        "outputId": "6bfd7ad0-5e4b-4c5c-f0d0-b98760c825cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eat\n",
            "eats  |  eat\n",
            "eat  |  eat\n",
            "ate  |  eat\n",
            "adjustable  |  adjustable\n",
            "rafting  |  raft\n",
            "ability  |  ability\n",
            "meeting  |  meeting\n",
            "better  |  well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_doc = \"\"\n",
        "for word in words:\n",
        "  new_doc = new_doc + \" \" + word\n",
        "\n",
        "new_doc = nlp(new_doc)\n",
        "\n",
        "for word in new_doc:\n",
        "  print(word, \"-->\", word.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU-GhhVbqj3l",
        "outputId": "ace787cd-fb17-4a28-e80a-ca3ff655c375"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -->  \n",
            "eating --> eat\n",
            "eats --> eat\n",
            "eat --> eat\n",
            "ate --> eat\n",
            "adjustable --> adjustable\n",
            "rafting --> raft\n",
            "ability --> ability\n",
            "meeting --> meeting\n",
            "dogs --> dog\n",
            "abaci --> abaci\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customizing lemmatizer"
      ],
      "metadata": {
        "id": "adMzWHeXvyIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wgUMtZGvGTj",
        "outputId": "86ddb2a9-1060-4ce4-c84b-85d713026e65"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ar = nlp.get_pipe('attribute_ruler')\n",
        "\n",
        "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Bruh\"}]],{\"LEMMA\":\"Brother\"})\n",
        "\n",
        "doc = nlp(\"Bro, you wanna go? Bruh, don't say no! I am exhausted\")\n",
        "for token in doc:\n",
        "    print(token.text, \"|\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1vHv30Mv2CS",
        "outputId": "46955e22-6adc-4d44-fd00-bb201a5f1898"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro | Brother\n",
            ", | ,\n",
            "you | you\n",
            "wanna | wanna\n",
            "go | go\n",
            "? | ?\n",
            "Bruh | Brother\n",
            ", | ,\n",
            "do | do\n",
            "n't | not\n",
            "say | say\n",
            "no | no\n",
            "! | !\n",
            "I | I\n",
            "am | be\n",
            "exhausted | exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZF5EBadwD-h",
        "outputId": "827436a9-df0a-4c28-be29-57523a665af9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bruh"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[6].lemma_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IBlE8R_HwEWD",
        "outputId": "c727a8ca-1bad-46ab-a5b1-651f99c99dc1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Brother'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "comQ-BwTwF-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}